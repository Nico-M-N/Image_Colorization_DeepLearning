digraph {
	graph [size="19.05,19.05"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2530382824784 [label="
 (1, 2, 256, 256)" fillcolor=darkolivegreen1]
	2530304292128 [label=TanhBackward0]
	2530382969584 -> 2530304292128
	2530382969584 [label=ConvolutionBackward0]
	2530381456400 -> 2530382969584
	2530381456400 [label=UpsampleNearest2DBackward0]
	2530381456256 -> 2530381456400
	2530381456256 [label=ReluBackward0]
	2530381455824 -> 2530381456256
	2530381455824 [label=ConvolutionBackward0]
	2530381455776 -> 2530381455824
	2530381455776 [label=UpsampleNearest2DBackward0]
	2530381458272 -> 2530381455776
	2530381458272 [label=ReluBackward0]
	2530381447856 -> 2530381458272
	2530381447856 [label=ConvolutionBackward0]
	2530381453232 -> 2530381447856
	2530381453232 [label=UpsampleNearest2DBackward0]
	2530381448096 -> 2530381453232
	2530381448096 [label=ReluBackward0]
	2530381457120 -> 2530381448096
	2530381457120 [label=ConvolutionBackward0]
	2530381455200 -> 2530381457120
	2530381455200 [label=ReluBackward0]
	2530382868640 -> 2530381455200
	2530382868640 [label=ConvolutionBackward0]
	2530382869024 -> 2530382868640
	2530382869024 [label=ReluBackward0]
	2530382868928 -> 2530382869024
	2530382868928 [label=ConvolutionBackward0]
	2530382869312 -> 2530382868928
	2530382869312 [label=ReluBackward0]
	2530382869216 -> 2530382869312
	2530382869216 [label=ConvolutionBackward0]
	2530382869600 -> 2530382869216
	2530382869600 [label=ReluBackward0]
	2530382869264 -> 2530382869600
	2530382869264 [label=ConvolutionBackward0]
	2530382869888 -> 2530382869264
	2530382869888 [label=ReluBackward0]
	2530382869792 -> 2530382869888
	2530382869792 [label=ConvolutionBackward0]
	2530382870176 -> 2530382869792
	2530382870176 [label=ReluBackward0]
	2530382870080 -> 2530382870176
	2530382870080 [label=ConvolutionBackward0]
	2530382870464 -> 2530382870080
	2530382822720 [label="encoder.0.weight
 (64, 1, 3, 3)" fillcolor=lightblue]
	2530382822720 -> 2530382870464
	2530382870464 [label=AccumulateGrad]
	2530382869840 -> 2530382870080
	2530382822640 [label="encoder.0.bias
 (64)" fillcolor=lightblue]
	2530382822640 -> 2530382869840
	2530382869840 [label=AccumulateGrad]
	2530382869552 -> 2530382869792
	2530382831744 [label="encoder.2.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2530382831744 -> 2530382869552
	2530382869552 [label=AccumulateGrad]
	2530382869408 -> 2530382869792
	2530382831664 [label="encoder.2.bias
 (128)" fillcolor=lightblue]
	2530382831664 -> 2530382869408
	2530382869408 [label=AccumulateGrad]
	2530382869504 -> 2530382869264
	2530383021152 [label="encoder.4.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2530383021152 -> 2530382869504
	2530382869504 [label=AccumulateGrad]
	2530382869120 -> 2530382869264
	2530383021312 [label="encoder.4.bias
 (256)" fillcolor=lightblue]
	2530383021312 -> 2530382869120
	2530382869120 [label=AccumulateGrad]
	2530382868976 -> 2530382869216
	2530383022272 [label="encoder.6.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2530383022272 -> 2530382868976
	2530382868976 [label=AccumulateGrad]
	2530382868832 -> 2530382869216
	2530383022352 [label="encoder.6.bias
 (512)" fillcolor=lightblue]
	2530383022352 -> 2530382868832
	2530382868832 [label=AccumulateGrad]
	2530382868688 -> 2530382868928
	2530383022512 [label="encoder.8.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	2530383022512 -> 2530382868688
	2530382868688 [label=AccumulateGrad]
	2530382868544 -> 2530382868928
	2530383022592 [label="encoder.8.bias
 (256)" fillcolor=lightblue]
	2530383022592 -> 2530382868544
	2530382868544 [label=AccumulateGrad]
	2530382868400 -> 2530382868640
	2530383022752 [label="decoder.0.weight
 (256, 512, 3, 3)" fillcolor=lightblue]
	2530383022752 -> 2530382868400
	2530382868400 [label=AccumulateGrad]
	2530382865088 -> 2530382868640
	2530383022832 [label="decoder.0.bias
 (512)" fillcolor=lightblue]
	2530383022832 -> 2530382865088
	2530382865088 [label=AccumulateGrad]
	2530381452608 -> 2530381457120
	2530383022992 [label="decoder.2.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2530383022992 -> 2530381452608
	2530381452608 [label=AccumulateGrad]
	2530381452752 -> 2530381457120
	2530383023072 [label="decoder.2.bias
 (256)" fillcolor=lightblue]
	2530383023072 -> 2530381452752
	2530381452752 [label=AccumulateGrad]
	2530381455680 -> 2530381447856
	2530383023232 [label="decoder.5.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2530383023232 -> 2530381455680
	2530381455680 [label=AccumulateGrad]
	2530381454864 -> 2530381447856
	2530383023312 [label="decoder.5.bias
 (128)" fillcolor=lightblue]
	2530383023312 -> 2530381454864
	2530381454864 [label=AccumulateGrad]
	2530381456160 -> 2530381455824
	2530383023472 [label="decoder.8.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2530383023472 -> 2530381456160
	2530381456160 [label=AccumulateGrad]
	2530381455872 -> 2530381455824
	2530383023552 [label="decoder.8.bias
 (64)" fillcolor=lightblue]
	2530383023552 -> 2530381455872
	2530381455872 [label=AccumulateGrad]
	2530381456064 -> 2530382969584
	2530383023712 [label="decoder.11.weight
 (2, 64, 3, 3)" fillcolor=lightblue]
	2530383023712 -> 2530381456064
	2530381456064 [label=AccumulateGrad]
	2530381456016 -> 2530382969584
	2530383023792 [label="decoder.11.bias
 (2)" fillcolor=lightblue]
	2530383023792 -> 2530381456016
	2530381456016 [label=AccumulateGrad]
	2530304292128 -> 2530382824784
}
